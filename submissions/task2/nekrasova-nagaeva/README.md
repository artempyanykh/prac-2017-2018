# Постановка задачи

*Считать данные из training.csv. Проверить является ли ряд стационарным в широком смысле: провести визуальную оценку или провести тест Дики - Фуллера. Оценить достоверность статистики.  
Разложить временной ряд на тренд, сезональность. Проверить является ли временной ряд интегрированным порядка k. Применить к нему модель ARIMA, подобрав необходимые параметры. Предсказать значения для тестовой выборки. Визуализировать их, посчитать r2 score для каждой из моделей. Произвести отбор наилучшей модели с помощью информационного критерия Акаике.*

***Временной ряд*** - совокупность наблюдений экономической величины в различные моменты времени.  
В нашем случае это последовательность случайных величин Value(t), где t ∈ \[01.01.1959, 01.12.1988\], Δt - месяц.  

***Стохастический процесс*** - конечная подпоследовательность бесконечной последовательности {X(t), t = 0, ±1, ±2, ...}. 
Временной ряд - это реализация некоторого стохастического процесса.

Рассмотрим случайный процесс X(w,t), где w - случай, t - время.  
Его статистической характеристикой является совокупность совместных функций распределения:  
{ f1( x(t1) ), f2( x(t1), x(t2) ), f3( x(t1), x(t2), x(t3) ), ...}  

Временной ряд называется ***строго стационарным*** (стационарным в узком смысле), если сдвиг во времени не меняет 
ни одну из функций распределения. Получается, что при каждом фиксированном моменте времени случайный процесс есть
случайная величина, и для каждой из них можно рассматривать E[X], Var[X], ... .  
(Подразумевается сходимость данных рядов)

Cov(X(t1), X(t2)) =  ∫ ∫ (x(t1) - EX) \* (x(t2) - EX) \* f2(x(t1), x(t2))dx(t1)dx(t2)  
Заменим разность (t1 - t2) на  τ. Совокупность значений ковариаций при всевозможных значениях между моментами 
времени называется автоковариационной функцией случайного процесса -  γ.  
Коэффициент корреляции ρ(τ) =  γ(τ) /  γ(0). Автокорреляционная функция показывает,
насколько статистически зависимы значения временного ряда при различных сдвигах времени.
В нашем случае - за месяц, за два месяца и т.д.

Если случайный процесс таков, что у него мат. ожидание и дисперсия существуют и не зависят от времени, а γ и ρ зависят только от τ, то такой процесс является ***стационарным в широком смысле***. Всякий стационарный в узком
смысле процесс стационарен в широком смысле. Обратное, вообще говоря, неверно.

Декомпозиция Вольда:  
Чисто недетерминированный стационарный в широком смысле случайный процесс X(t) может быть представлен  в виде
X(t) - E\[X(t)\] = ∑ ψ(t) \* ε(t - τ), t = \[0, ∞)  
где ε(j) - белый шум с конечными мат. ожиданием и дисперсией.  
То есть всякий стационарный процесс в общеем смысле представляется в виде линейной комбинации белых шумов
с разными весовыми коэффициентами.

***Оператор сдвига ℒ***: ℒX(t) = X(t-1);  
(ℒ^p)X(t) = ℒ(ℒ(ℒ...)X(t) = X(t-p), (ℒ^0)X(t) = X(t).

Если значение случайного процесса определяется линейной комбинацией конечного числа его предыдущих значений и добавлением белого шума, то такой процесс называется ***процессом авторегрессии порядка p*** и его общее уравнение имеет вид  
X(t) = α1\*X(t-1) + α2\*X(t-2) + ... + αp\*X(t-p) + εi, где εi - белый шум.

Стохастический процесс называется ***процессом скользящего среднего порядка q***, если в разложении Вольда
присутствуют только q первых слагаемых. Название "скользящее среднее" объяснено тем, что текущее значение случайного процесса определяется взвешенным средним q предыдущих значений белого шума. - MA(q)

MA(q) :  
X(t) = ∑ β(τ) * ε(t-τ),  τ = \[0, q]   
X(t) = ( 1 + β1ℒ + ... + βq(ℒ^q) ) \* ε(t) = βq(ℒ)(t)
X(t) = βq ∏ (ℒ - Zi), i = \[1, q], где Zi - корни уравнения 1 + β1Z + ... + βq(Z^q) = 0  
Характретистическое уравнение λ^q + β1\*λ^(q-1) + ... βq+ = 0, его корни - πi.  
ε(t) =  {1 / ∏(1 - πiℒ)} \* X(t), => |πi| < 1 - условие обратимости процесса МА.  
(ε(t будет выражено через прошлые значения X(t))


Процесс, обратный к MA(q) обозначается AR(∞). Если процесс AR стационарен, то он кроме конечного представления AR(p) имеет и бесконечное представление MA(∞). И если выполнено условие обратимости, то конечный процесс MA(q) имеет бесконечное представление AR(∞).

Все корни характеристического уравнения для процесса AR(p) лежат внутри единичного круга <=> ряд стационарен.

***Частная автокорреляционная функция ρ(τ)*** = 1/(Var\[X(t)])  \*  E\[ (X(t) - EX)(X(t-τ) - EX) \]  
Она показывает коэффициент корреляции между X(t-k) и X(t) за вычетом той части x(t), которая линейно объяснена промежуточными лагами x(t-1), x(t-2), ... , x(t-k-1).  
***Лаг*** - момент времени один шаг назад.  
PACF ρ(k) авторегрессионного процeсса AR(p) равна 0 для k>p.

Процесс авторегрессии скользящего среднего ARMA:  
X(t) = α1\*X(t-1) + ... + αp\*X(t-p) + ε(t) + β1\*ε(t-1) + ... + βq\*ε(t-q)

Если ряд после взятия d последовательных разностей приводится к стационарному, он ***интегрированный порядка d***.

ARIMA - процесс авторегрессии - интегрированного скользящего среднего.  
αp(ℒ)(Δ^d)x(t) = βq(ℒ)ε(t)

#### Тест Дики-Фуллера

Временной ряд имеет единичный корень, если его первые разности образуют стационарный ряд.

X(t)-X(t-1)= gX(t-1) + ε(t)

Нулевая гипотеза H0: g = 0 (существует единичный корень, ряд нестационарный).

Альтернативная гипотеза: H1: g < 0 (единичного корня нет, ряд стационарный).

Отвергаем H0 на N процентном (N=1%, 5%, 10%) уровне значимости, если t0<tN(крит.)

***Достоверность статистики (p-value)*** - мера уверенности в корректности результата. Чем p-value меньше, тем больше доверия.

***Коэффициент детерминации ( R^2 — R-квадрат)*** — это доля дисперсии зависимой переменной, объясняемая рассматриваемой моделью зависимости, то есть объясняющими переменными. Более точно — это единица минус доля необъяснённой дисперсии (дисперсии случайной ошибки модели, или условной по факторам дисперсии зависимой переменной) в дисперсии зависимой переменной. Его рассматривают как универсальную меру зависимости одной случайной величины от множества других.

***Критерий AIC (Akaike information criterion)*** для модели ARMA(p,q):  
AIC(p,q) = ln(σ^2) + 2(p+q)/T, где T - число наблюдений,  σ^2 = RSS/(T-p-q),  
RSS = ∑ (x(t) - x'(t))^2, t ∈ \[1, n], где x(t) - фактические значения объясняемой переменной,  
x'(t) - расчетные значения.


# Решение задачи

Потребуются некоторые библиотеки, скачиваем их с помощью pip3:

    sudo pip3 install numpy
    sudo pip3 install pandas
    sudo pip3 install matplotlib
    sudo pip3 install statsmodels
    sudo pip3 install sklearn
  
Для красоты и дополнительных баллов добавим seaborn
 
    sudo pip3 install seaborn
    
Заходим в директорию, содержащую файлы *testing.csv* , *training.csv* , *task_2.ipynb*.

    jupyter notebook task_2.ipynb

## Подзадача 1 

Считываем данные из *training.csv* , в котором хранится временной ряд. Указываем, что нужно различать 'Date' и 'Value', 
где столбец 'Date' - время :

> d_set = pd.read_csv('training.csv', index_col=['Date'], parse_dates=['Date'])

Визуализируем статистику, построенную по заданному ряду с помощью функции  
`def check_stationarity_graph(d_set)`

Отрисуем скользящие средние для разных размеров "окна" - год и 5 лет:

> dma_set_y = d_set.rolling(12).mean()

> dma_set_fy = d_set.rolling(60).mean()

Построим вариацию, стандартное отклонение и ковариацию для окна в год: 

> dmv_set = d_set.rolling(12).var()

> dms_set = d_set.rolling(12).std()

> dmcv_set = d_set.rolling(12).cov(d_set)


Оценим стационарность ряда с помощью теста Дики-Фуллера `def check_stationarity_DF(dset)` :

> DF_test = smt.adfuller(dset.dropna())

Метод `dropna` возвращает объект, в котором нет значений ряда, если они не определены (NaN).

Также воспользуемся p-value, полученного при применении ДФ-теста. Предполагаем, что статистика и ряд независимые.
Тогда вероятность получить такие результаты = p-value. Это оценка нашей статистики.

## Подзадача 2

Тренд — тенденция изменения показателей временного ряда.  
Сезонность - периодически колебания, наблюдаемые на временных рядах.

Разложим ряд в аддитивную модель:
> addit_m = sms.seasonal_decompose(d_set['Value'], model='additive')

Считаем, что наш ряд раскладывается в сумму трех рядов - тренда, сезональности и остатка.
Тренд получается нестационарным, а сезональность и остаток стационарными. 
Этот результат дает нам право работать с остатком: учить модель предсказывать по нему, а затем к получившемуся результату 
добавить ряды тренда и сезональности.

Теперь получим разложение в мультипликативную модель с помощью
> multi_m = sms.seasonal_decompose(d_set['Value'], model='multiplicative')

Здесь ряд данных представляется в виде произведения тренда, сезональности и остатка.
С помощью визуализации видим различия сезональности и остатка, 
но результаты стационарности сохраняются - можем работать аналогично.

## Подзадача 3

Определим порядок интегрированности ряда. Для этого сначала возьмем разности значений ряда с периодом = 1,
воспользуемся методом `diff` :
> d_set_diff = dset\['Value'\].diff(periods=k).dropna()

Проверив ДФ-тестом получившийся ряд, убедились в его стационарности  - по определению интегрированного ряда порядка 1, 
`d_set_diff` именно такого порядка. => Получили параметр d для модели ARIMA(p,d,q)

Для определения других параметров этой модели получим для `d_set_diff` графики автокорреляционной и частичной
автокорреляционной функций.
ACF затухает по синусоиде. PACF имеет выброс на лаге 1, для прочих лагов корреляции нет - оптимальная модель при 
p = 1, q = 0. (Что станет видно при сравнении графиков предсказаний)

Для сравнения построим различные модели ARIMA:

> model1 = sma.ARIMA(d_set, order=(1, 1, 1)).fit()

> model2 = sma.ARIMA(d_set, order=(1, 1, 0)).fit()

> model3 = sma.ARIMA(d_set, order=(1, 1, 2)).fit()

Для каждой модели построим предсказание методом `predict` с параметрами начала, конца и типа:

> pred3 = model3.predict('1989-01-01', '1993-12-01', typ='levels')

Графики предсказаний очень похожи, модель (1, 1, 0) чуть лучше.  

#### Показатели R^2  

Основная проблема применения R^2 заключается в том, что его значение увеличивается (не уменьшается) от добавления в модель новых переменных, даже если эти переменные никакого отношения к объясняемой переменной не имеют. Чем ближе R^2 к 1, тем выше качество модели.
В нашем случае все R^2 для моделей ARIMA отрицательные. Наибольший R^2 = -3.06 у ARIMA(1, 1, 0).

#### Критерий Акаике

Выбирается та модель, для которой значение критерия минимально. В нашем случае это ARIMA(0, 1, 4), для которой AIC = 245.01

### Построение SARIMAX

Для улучшения прогноза временного ряда мы решили использовать модель SARIMAX(p, d, q)(P, D, Q, S), так у нашего ряда ярко выраженная сезонность.

S: период сезона  
D: порядок сезонного дифференцирования ряда  
d: порядок дифференцирования ряда  
q: номер последнего лага τ < S, при котором автокорреляция значима  
Q ∗ S: номер последнего сезонного лага, при котором автокорреляция значима  
p: номер последнего лага τ < S, при котором частичная автокорреляция значима  
P ∗ S: номер последнего сезонного лага, при котором частичная автокорреляция значима  

### Seaborn

Из библиотеки ***seaborn*** используются следующие функции:

> sb.set_context("talk", rc={"lines.linewidth": 3})

Устанавливает "talk", который частично влияет на толщину линий, размер названий и другие элементы рисунка

> sb.set_palette("husl", 5)

Устанавливает палитру husl из 5 цветов

> sb.despine()

Убирает правый верхний угол рамки рисунка


## Задание выполняли Некрасова Мария и Нагаева Варвара, группа 312

Некрасова Мария:

1. Проверка стационарности графика: визуальная, тест Дики-Фуллера;  
2. Достоверность статистики;  
3. Разложение временного ряда на тренд и сезональность;  
4. ARIMA-модели, предсказания;  
5. Критерий AIC;  
6. SARIMAX-модели;  

Нагаева Варвара:

1. Проверка стационарности графика визуальная;  
2. Достоверность статистики;  
3. Проверка является ли временной ряд интегрированным порядка k;  
4. Построение автокорреляционной и частной автокорреляционной функций;  
5. ARIMA-модели, предсказания;  
6. R^2 score;  
